{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b6225b",
   "metadata": {},
   "source": [
    "# Telecom Churn Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103ca7f",
   "metadata": {},
   "source": [
    "## Step 1: Importing and Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac79ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61592fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc937af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all datasets\n",
    "churn_data = pd.read_csv(\"churn_data.csv\")\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76deae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.read_csv(\"customer_data.csv\")\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_data= pd.read_csv('internet_data.csv')\n",
    "internet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e876f41",
   "metadata": {},
   "source": [
    "#### If you have analysis the data the first column which is customerID tops 5 rows are sane in all the data set so out next step will merger the data and create single data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d4e46",
   "metadata": {},
   "source": [
    "## Combining all data files into one consolidated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ae9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging on 'customerID'\n",
    "df_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe with all predictor variables\n",
    "telecom = pd.merge(df_1, internet_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea509d",
   "metadata": {},
   "source": [
    "## Step 2: Inspecting the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed697c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57114b9",
   "metadata": {},
   "source": [
    "## Step 3: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the type of each column\n",
    "telecom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to map\n",
    "\n",
    "varlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']\n",
    "\n",
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'Yes': 1, \"No\": 0})\n",
    "\n",
    "# Applying the function to the housing list\n",
    "telecom[varlist] = telecom[varlist].apply(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7934ef",
   "metadata": {},
   "source": [
    "### For categorical variable with multiple levels, create dummy features (on-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e08891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy variable for some of the categorical variables and dropping the first one.\n",
    "dummy1 = pd.get_dummies(telecom[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom, dummy1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4356e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n",
    "\n",
    "# Creating dummy variables for the variable 'MultipleLines'\n",
    "ml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')\n",
    "# Dropping MultipleLines_No phone service column\n",
    "ml1 = ml.drop(['MultipleLines_No phone service'], 1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ml1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'OnlineSecurity'.\n",
    "os = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')\n",
    "os1 = os.drop(['OnlineSecurity_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,os1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'OnlineBackup'.\n",
    "ob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')\n",
    "ob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ob1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'DeviceProtection'. \n",
    "dp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')\n",
    "dp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,dp1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'TechSupport'. \n",
    "ts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')\n",
    "ts1 = ts.drop(['TechSupport_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ts1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'StreamingTV'.\n",
    "st =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')\n",
    "st1 = st.drop(['StreamingTV_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,st1], axis=1)\n",
    "\n",
    "# Creating dummy variables for the variable 'StreamingMovies'. \n",
    "sm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')\n",
    "sm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n",
    "# Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,sm1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17a284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522424f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created dummies for the below variables, so we can drop them\n",
    "telecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'TotalCharges' column from string to float\n",
    "telecom['TotalCharges'] = pd.to_numeric(telecom['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472aefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c1caa",
   "metadata": {},
   "source": [
    "#### Checking Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "num_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "num_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589697c",
   "metadata": {},
   "source": [
    "From the distribution shown above, you can see that there no outliers in the dataset. the number should be increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507def99",
   "metadata": {},
   "source": [
    "#### Checking for Missing Values and Inputing Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the up the missing values\n",
    "telecom.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15497491",
   "metadata": {},
   "source": [
    "it means that is 11/7043=0.00156183444 i.e 0.1% best is to remove these observation form analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the prcentage of missing value\n",
    "round(100*(telecom.isnull().sum()/len(telecom.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN TotalCharges rows\n",
    "telecom = telecom[~np.isnan(telecom['TotalCharges'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa90363",
   "metadata": {},
   "source": [
    "Now we don't have missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc103039",
   "metadata": {},
   "source": [
    "## Step 4: Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = telecom.drop(['Churn','customerID'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6140c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = telecom['Churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d51c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6595f4",
   "metadata": {},
   "source": [
    "## Step 5: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf89b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking the Churn Rate\n",
    "churn = (sum(telecom['Churn'])/len(telecom['Churn'].index))*100\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a967d2",
   "metadata": {},
   "source": [
    "We have almost 27% churn rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7022f",
   "metadata": {},
   "source": [
    "## Step 6: Looking at Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74017006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(telecom.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f2e02",
   "metadata": {},
   "source": [
    "#### Dropping highly correlated dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df663cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n",
    "                       'StreamingTV_No','StreamingMovies_No'], 1)\n",
    "X_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n",
    "                         'StreamingTV_No','StreamingMovies_No'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe92f1",
   "metadata": {},
   "source": [
    "#### Checking the Correlation Matrix\n",
    "\n",
    "After dropping the highly correlated variable now let's check the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(X_train.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d709d",
   "metadata": {},
   "source": [
    "## Step 7: Model Building\n",
    "\n",
    "Let's start by splitting our data into a training set and a test set.\n",
    "\n",
    "### Running Your First Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903c465",
   "metadata": {},
   "source": [
    "## Step 8: Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474db32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=15)            # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "      # running RFE with 13 variables as output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ca095",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcce91",
   "metadata": {},
   "source": [
    "#### Assessing the model with StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e88ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1324e",
   "metadata": {},
   "source": [
    "#### Creating a dataframe with the actual churn flag and the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc772b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final['CustID'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb82236",
   "metadata": {},
   "source": [
    "#### Creating new column 'predicted with 1 if churn_Prob>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd630a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87072e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted     not_churn    churn\n",
    "# Actual\n",
    "# not_churn        3270      365\n",
    "# churn            579       708  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "print(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f2380",
   "metadata": {},
   "source": [
    "#### Checking VIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f668818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif[\"VIF\"]=round(vif['VIF'],2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dadd7a",
   "metadata": {},
   "source": [
    "#### There are a few variables with high VIF. It's best to drop these variables as they aren't helping much with prediction and unnecessarily making the model complex. The variable 'MonthlyCharges' has the highest VIF. So let's start by dropping that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabe8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop(['MonthlyCharges'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-un the model using the selected Variable\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train, X_train_sm, famliy = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res.predict(X_train_sm).values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Churn_Prob'] = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13db3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x>0.5 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99285590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Check the overall accuracy\n",
    "print(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb033870",
   "metadata": {},
   "source": [
    "So overall the accuracy has dropped much\n",
    "\n",
    "#### Let Check the VIF again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"Features\"] = X_train[col].columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_train[col].values, 1) for i in range(X_train[col].shape[1])]\n",
    "vif[\"VIF\"] = round(vif[\"VIF\"],2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb69651",
   "metadata": {},
   "source": [
    "All variables have a good value of VIF. So we need not drop any more variables and we can proceed with making predictions using this model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn,y_train_pred_final.predicted)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual/Predicted     not_churn    churn\n",
    "        # not_churn        3294     341\n",
    "        # churn            627       660  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eeffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "metrics.accuracy_score(y_train_pred_final.Churn,y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050226d",
   "metadata": {},
   "source": [
    "## Metrics beyond simply Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive\n",
    "TN = confusion[0,0] # true negative\n",
    "FP = confusion[0,1] # false positive\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sentivity of logisitic regression model.\n",
    "TP/float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's us calculate specificity\n",
    "TN/ float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fale positve rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513de3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive predictive value\n",
    "print(TP/float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80908128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predicitve value\n",
    "print(TN/ float(TN+FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c0b36",
   "metadata": {},
   "source": [
    "## Step 9: Plotting yhe ROC Curve\n",
    "\n",
    "An ROC Curve demonstrates several things:\n",
    "- It shows the tradeoff between sentivity and specificity (any increase in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1d1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
